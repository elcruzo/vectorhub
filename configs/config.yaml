server:
  grpc_port: 50051
  metrics_port: 9090
  max_message_size_mb: 100
  max_concurrent_streams: 1000
  connection_timeout_seconds: 30
  keepalive_time_seconds: 10
  keepalive_timeout_seconds: 5
  tls_enabled: false

redis:
  addresses:
    - "localhost:6379"
    - "localhost:6380"
    - "localhost:6381"
    - "localhost:6382"
  password: ""
  db: 0
  pool_size: 100
  min_idle_conns: 10
  max_retries: 3
  dial_timeout_seconds: 5
  read_timeout_seconds: 3
  write_timeout_seconds: 3
  cluster_mode: false
  sentinel_mode: false

sharding:
  shard_count: 8
  replica_count: 2
  virtual_nodes: 150
  health_check_interval_seconds: 10
  rebalance_enabled: true
  rebalance_interval_minutes: 60

replication:
  factor: 2
  sync_interval_seconds: 5
  max_lag_seconds: 30
  failover_timeout_seconds: 60
  replica_addresses:
    - "localhost:6380"
    - "localhost:6381"
  async_replication: true
  compression_enabled: false

metrics:
  enabled: true
  namespace: "vectorhub"
  subsystem: "server"
  histogram_buckets:
    - 0.001
    - 0.005
    - 0.01
    - 0.025
    - 0.05
    - 0.1
    - 0.25
    - 0.5
    - 1
    - 2.5
    - 5
    - 10
  collection_interval_seconds: 10
  enable_detailed_metrics: true

logging:
  level: "info"
  format: "json"
  output_path: "stdout"
  error_output_path: "stderr"
  enable_stacktrace: false
  enable_caller: true
  enable_sampling: false
  sampling_initial: 100
  sampling_thereafter: 100

performance:
  max_cpu: 0  # 0 means use all available CPUs
  max_memory_gb: 8
  enable_profiling: false
  profiling_port: 6060
  gc_percent: 100
  enable_memory_limit: true
  vector_cache_size_mb: 1024
  index_cache_size_mb: 512
  query_cache_enabled: true
  query_cache_ttl_seconds: 60